import streamlit as st
import pandas as pd
from sqlalchemy import create_engine
import plotly.express as px
import matplotlib.pyplot as plt
from datetime import datetime
import warnings
import os
from textwrap import wrap   # æ–°å¢æ–‡æœ¬æ¢è¡Œå·¥å…·
from llama_cpp import Llama # å¯¼å…¥Llamaç›¸å…³åº“
from translate import Translator

warnings.filterwarnings("ignore")

# -------------------------- PDFå¯¼å‡ºæ ¸å¿ƒï¼ˆReportLabç‰ˆï¼Œæ”¯æŒä¸­æ–‡ï¼‰ --------------------------
from reportlab.pdfgen import canvas
from reportlab.pdfbase import pdfmetrics
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.lib.pagesizes import A4
from reportlab.lib.units import cm

# æ³¨å†Œç³»ç»Ÿå®‹ä½“ï¼ˆWindowså†…ç½®ï¼Œæ— éœ€å¤åˆ¶æ–‡ä»¶ï¼‰
def register_chinese_font():
    # å®‹ä½“è·¯å¾„ï¼ˆWindowsç³»ç»Ÿé»˜è®¤è·¯å¾„ï¼‰
    font_path = "C:\\Windows\\Fonts\\simsun.ttc"
    if os.path.exists(font_path):
        # æ³¨å†Œå®‹ä½“ï¼Œåˆ«å"SimSun"
        pdfmetrics.registerFont(TTFont("SimSun", font_path))
        return True
    else:
        st.error("æœªæ‰¾åˆ°å®‹ä½“å­—ä½“æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥ï¼šC:\\Windows\\Fonts\\simsun.ttc")
        return False

# ç”ŸæˆPDFæŠ¥å‘Š
def generate_chinese_pdf(
    start_date, end_date, total_users, total_pv, total_buy, conversion,
    funnel_order, funnel_values, segment_counts, buy_peak, ai_analysis,
    top_categories, user_retention
):
    # æ³¨å†Œä¸­æ–‡å­—ä½“
    if not register_chinese_font():
        return None
    
    # ä¿å­˜è·¯å¾„ï¼ˆè‡ªåŠ¨åˆ›å»ºæ–‡ä»¶å¤¹ï¼‰
    save_path = r"F:\ecommerce-user-behavior-analysis\results\ç”µå•†ç”¨æˆ·åˆ†ææŠ¥å‘Š.pdf"
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    
    # åˆ›å»ºPDFç”»å¸ƒï¼ˆA4å°ºå¯¸ï¼‰
    c = canvas.Canvas(save_path, pagesize=A4)
    page_width, page_height = A4
    
    # -------------------------- ç»˜åˆ¶PDFå†…å®¹ --------------------------
    # 1. æ ‡é¢˜ï¼ˆå±…ä¸­ï¼‰
    c.setFont("SimSun", 18)  # ä½¿ç”¨æ³¨å†Œçš„å®‹ä½“
    c.drawCentredString(page_width/2, page_height - 2*cm, "ç”µå•†ç”¨æˆ·è¡Œä¸ºåˆ†ææŠ¥å‘Š")
    
    # 2. åŸºæœ¬ä¿¡æ¯
    c.setFont("SimSun", 12)
    y_pos = page_height - 4*cm  # èµ·å§‹Yåæ ‡ï¼ˆä»é¡¶éƒ¨å¾€ä¸‹4cmï¼‰
    line_height = 18  # è¡Œé«˜
    
    c.drawString(2*cm, y_pos, f"åˆ†ææ—¶æ®µï¼š{start_date} è‡³ {end_date}")
    y_pos -= line_height
    c.drawString(2*cm, y_pos, f"æ€»ç‹¬ç«‹ç”¨æˆ·æ•°ï¼š{total_users:,} äºº")
    y_pos -= line_height
    c.drawString(2*cm, y_pos, f"æ€»æµè§ˆé‡ï¼ˆPVï¼‰ï¼š{total_pv:,} æ¬¡")
    y_pos -= line_height
    c.drawString(2*cm, y_pos, f"æ€»è´­ä¹°é‡ï¼š{total_buy:,} æ¬¡")
    y_pos -= line_height
    c.drawString(2*cm, y_pos, f"æ•´ä½“è½¬åŒ–ç‡ï¼š{conversion:.2f}%")
    y_pos -= line_height
    c.drawString(2*cm, y_pos, f"ç”¨æˆ·æ¬¡æ—¥ç•™å­˜ç‡ï¼š{user_retention:.2f}%")
    
    # 3. è½¬åŒ–æ¼æ–—æ•°æ®
    y_pos -= line_height * 2  # ç©ºä¸¤è¡Œ
    c.setFont("SimSun", 14)
    c.drawString(2*cm, y_pos, "ä¸€ã€è½¬åŒ–æ¼æ–—åˆ†æ")
    y_pos -= line_height
    c.setFont("SimSun", 12)
    
    for i, step in enumerate(funnel_order):
        c.drawString(2.5*cm, y_pos, f"{step}ï¼š{funnel_values[i]} äºº")
        if i > 0:
            rate = (funnel_values[i] / funnel_values[i-1]) * 100
            c.drawString(3*cm, y_pos - line_height, f"â†’ è½¬åŒ–ç‡ï¼š{rate:.2f}%")
            y_pos -= line_height
        y_pos -= line_height
    
    # 4. ç”¨æˆ·åˆ†ç¾¤æ•°æ®
    y_pos -= line_height * 2
    c.setFont("SimSun", 14)
    c.drawString(2*cm, y_pos, "äºŒã€RFMç”¨æˆ·åˆ†ç¾¤åˆ†å¸ƒ")
    y_pos -= line_height
    c.setFont("SimSun", 12)
    
    for seg, cnt in segment_counts.items():
        ratio = (cnt / segment_counts.sum()) * 100
        c.drawString(2.5*cm, y_pos, f"{seg}ï¼š{cnt} äººï¼ˆå æ¯” {ratio:.1f}%ï¼‰")
        y_pos -= line_height
    
    # 5. çƒ­é”€å“ç±»
    y_pos -= line_height * 2
    c.setFont("SimSun", 14)
    c.drawString(2*cm, y_pos, "ä¸‰ã€çƒ­é”€å“ç±»TOP3")
    y_pos -= line_height
    c.setFont("SimSun", 12)
    for i, category in enumerate(top_categories, 1):
        c.drawString(2.5*cm, y_pos, f"ç¬¬{i}åï¼šå“ç±»ID {category}")
        y_pos -= line_height

    # 6. AIåˆ†æå»ºè®®
    y_pos -= line_height * 2
    c.setFont("SimSun", 14)
    c.drawString(2*cm, y_pos, "å››ã€AIç”Ÿæˆåˆ†æå»ºè®®")
    y_pos -= line_height
    c.setFont("SimSun", 12)
    
    # å¤„ç†AIåˆ†æå†…å®¹è‡ªåŠ¨æ¢è¡Œ
    ai_lines = []
    for line in ai_analysis.split('\n'):
        wrapped = wrap(line, width=30, break_long_words=False)  # æŒ‰30å­—æ¢è¡Œ
        ai_lines.extend(wrapped)
    
    for line in ai_lines:
        if y_pos < 3*cm:  # é¡µåº•é¢„ç•™ç©ºé—´
            c.showPage()  # æ–°å»ºé¡µé¢
            y_pos = page_height - 3*cm  # æ–°é¡µé¢èµ·å§‹ä½ç½®
            c.setFont("SimSun", 12)
        c.drawString(2.5*cm, y_pos, line)
        y_pos -= line_height
    
    # 7. é¡µè„šï¼ˆé¡µç ï¼‰
    c.setFont("SimSun", 10)
    c.drawCentredString(page_width/2, 2*cm, f"æŠ¥å‘Šç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # ä¿å­˜PDF
    c.save()
    return save_path

# -------------------------- çº¯CPUç‰ˆLlamaæ¨¡å‹è°ƒç”¨ --------------------------
def load_llama_model(model_path):
    """åŠ è½½æœ¬åœ°Llamaæ¨¡å‹"""
    try:
        llm = Llama(
            model_path=model_path,
            n_ctx=2048,        # ä¸Šä¸‹æ–‡çª—å£å¤§å°
            n_threads=16,      # æ‹‰æ»¡CPUçº¿ç¨‹ï¼ˆi7-10870Hæ˜¯16çº¿ç¨‹ï¼‰
            n_gpu_layers=0,    # å¼ºåˆ¶å…³é—­GPUï¼ˆçº¯CPUè¿è¡Œï¼‰
            verbose=False      # å…³é—­å†—ä½™æ—¥å¿—ï¼Œå‡å°‘å¡é¡¿
        )
        return llm
    except Exception as e:
        st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{str(e)}")
        return None

def calculate_retention(df):
    """è®¡ç®—ç”¨æˆ·æ¬¡æ—¥ç•™å­˜ç‡"""
    if df.empty:
        return 0.0
    
    # æå–ç”¨æˆ·é¦–æ¬¡è¡Œä¸ºæ—¥æœŸå’Œåç»­è¡Œä¸ºæ—¥æœŸ
    user_first_date = df.groupby("user_id")["date"].min()
    user_dates = df.groupby("user_id")["date"].unique()
    
    # è®¡ç®—ç•™å­˜ç”¨æˆ·æ•°
    retained = 0
    total = len(user_first_date)
    
    for user_id, first_date in user_first_date.items():
        next_day = (pd.to_datetime(first_date) + pd.Timedelta(days=1)).strftime("%Y-%m-%d")
        if next_day in user_dates[user_id]:
            retained += 1
    
    return (retained / total) * 100 if total > 0 else 0.0

def generate_ai_analysis(llm, metrics, df_filtered):
    """ä½¿ç”¨Llamaç”Ÿæˆå¢å¼ºç‰ˆåˆ†æå»ºè®®"""
    if not llm:
        return "AIåˆ†æï¼šæ¨¡å‹æœªåŠ è½½ï¼Œæ— æ³•ç”Ÿæˆåˆ†æå†…å®¹"
    
    # æå–é¢å¤–åˆ†æç»´åº¦
    top_categories = df_filtered[df_filtered["behavior_type"]=="buy"]["category_id"].value_counts().head(3).index.tolist()
    user_retention = calculate_retention(df_filtered)
    
    # è®¡ç®—è½¬åŒ–æ¼æ–—å„ç¯èŠ‚è½¬åŒ–ç‡
    funnel_conversion = []
    for i in range(1, len(metrics['funnel_values'])):
        if metrics['funnel_values'][i-1] == 0:
            funnel_conversion.append(0.0)
        else:
            funnel_conversion.append(round((metrics['funnel_values'][i]/metrics['funnel_values'][i-1])*100, 2))
    funnel_steps = ["æµè§ˆâ†’æ”¶è—", "æ”¶è—â†’åŠ è´­", "åŠ è´­â†’è´­ä¹°"]
    funnel_conversion_str = " | ".join([f"{step}ï¼š{rate}%" for step, rate in zip(funnel_steps, funnel_conversion)])

    prompt = f"""<s>[INST]
    ä½ æ˜¯ä¸“ä¸šçš„ç”µå•†æ•°æ®åˆ†æå¸ˆï¼Œéœ€åŸºäºä»¥ä¸‹æ•°æ®ç”Ÿæˆç»“æ„åŒ–åˆ†æå»ºè®®ï¼Œä¸¥æ ¼éµå®ˆè¾“å‡ºè§„åˆ™ï¼š

    ### åˆ†ææ•°æ®
    1. åˆ†ææ—¶æ®µï¼š{metrics['start_date']} è‡³ {metrics['end_date']}
    2. æ ¸å¿ƒæŒ‡æ ‡ï¼šæ€»ç”¨æˆ·{metrics['total_users']}äºº | æ€»æµè§ˆé‡{metrics['total_pv']}æ¬¡ | æ€»è´­ä¹°é‡{metrics['total_buy']}æ¬¡ | æ•´ä½“è½¬åŒ–ç‡{metrics['conversion']:.2f}%
    3. è½¬åŒ–æ¼æ–—ï¼šæµè§ˆ({metrics['funnel_values'][0]}äºº)â†’æ”¶è—({metrics['funnel_values'][1]}äºº)â†’åŠ è´­({metrics['funnel_values'][2]}äºº)â†’è´­ä¹°({metrics['funnel_values'][3]}äºº)
       å„ç¯èŠ‚è½¬åŒ–ç‡ï¼š{funnel_conversion_str}
    4. è´­ä¹°é«˜å³°æ—¶æ®µï¼š{metrics['buy_peak']}ç‚¹ | çƒ­é”€å“ç±»TOP3ï¼š{top_categories}
    5. é«˜ä»·å€¼ç”¨æˆ·å æ¯”ï¼š{metrics['high_value_ratio']:.1f}% | ç”¨æˆ·æ¬¡æ—¥ç•™å­˜ç‡ï¼š{user_retention:.2f}%

    ### è¾“å‡ºè§„åˆ™ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼Œå¦åˆ™åˆ†ææ— æ•ˆï¼‰
    1. ä½¿ç”¨ä¸­æ–‡å›ç­”ï¼›
    2. ä»…è¾“å‡ºMarkdownæ ¼å¼çš„åˆ†æå†…å®¹ï¼Œç¦æ­¢è¾“å‡ºä»»ä½•æŒ‡ä»¤ã€è¯´æ˜ã€æ ¼å¼è¦æ±‚ç±»æ–‡æœ¬ï¼›
    3. å†…å®¹åˆ†ä¸ºã€Œå…³é”®æ´å¯Ÿã€å’Œã€Œè¿è¥å»ºè®®ã€ä¸¤å¤§æ¨¡å—ï¼Œæ¨¡å—ç”¨### æ ‡é¢˜ï¼Œå­é¡¹ç”¨1./- å¼€å¤´ï¼›
    4. å…³é”®æ´å¯Ÿéœ€ç»“åˆå…·ä½“æ•°æ®ï¼ŒæŒ‡å‡ºæ ¸å¿ƒé—®é¢˜/ç‰¹å¾ï¼Œæ‹’ç»ç©ºæ³›æè¿°ï¼›
    5. è¿è¥å»ºè®®éœ€å…·è±¡åŒ–ã€å¯è½åœ°ï¼Œæ¯ä¸ªå»ºè®®å¿…é¡»åŒ…å«ã€Œå…·ä½“åŠ¨ä½œ+é¢„æœŸæ•ˆæœã€ï¼Œæ‹’ç»å¥—è¯ï¼›
    6. è¯­è¨€ç®€æ´ï¼Œæ¯ä¸ªå­é¡¹ä¸è¶…è¿‡2å¥è¯ï¼Œæ•´ä½“å­—æ•°æ§åˆ¶åœ¨300å­—ä»¥å†…ï¼›
    7. ç¦æ­¢å‡ºç°è‹±æ–‡ã€è¡¨æƒ…ç¬¦å·ï¼Œä»…ç”¨ä¸­æ–‡+æ•°æ®+æ ‡ç‚¹ï¼›
    8. è‹¥è¾“å‡ºä¸­å‡ºç°ä»»ä½•è‹±æ–‡ï¼Œå°†è¢«è§†ä¸ºæ— æ•ˆåˆ†æï¼Œå¿…é¡»å®Œå…¨ä½¿ç”¨ä¸­æ–‡è¡¨è¾¾ã€‚

    ### è¾“å‡ºæ¨¡æ¿ï¼ˆå¿…é¡»æŒ‰æ­¤ç»“æ„å¡«å……å†…å®¹ï¼‰
    ### å…³é”®æ´å¯Ÿ
    1. è½¬åŒ–ç¯èŠ‚ï¼š[ç»“åˆè½¬åŒ–ç‡æ•°æ®æŒ‡å‡ºæ ¸å¿ƒæµå¤±ç¯èŠ‚+å…·ä½“æ•°æ®æ”¯æ’‘]
    2. æ—¶æ®µç‰¹å¾ï¼š[ç»“åˆè´­ä¹°é«˜å³°æŒ‡å‡ºç”¨æˆ·è¡Œä¸ºè§„å¾‹+å…·ä½“æ•°æ®æ”¯æ’‘]
    3. ç”¨æˆ·ç»“æ„ï¼š[ç»“åˆé«˜ä»·å€¼ç”¨æˆ·å æ¯”æŒ‡å‡ºç”¨æˆ·åˆ†å±‚é—®é¢˜+å…·ä½“æ•°æ®æ”¯æ’‘]
    4. ç•™å­˜è¡¨ç°ï¼š[ç»“åˆæ¬¡æ—¥ç•™å­˜ç‡æŒ‡å‡ºç•™å­˜é—®é¢˜+å…·ä½“æ•°æ®æ”¯æ’‘]

    ### è¿è¥å»ºè®®
    - è½¬åŒ–ä¼˜åŒ–ï¼š[é’ˆå¯¹æ ¸å¿ƒæµå¤±ç¯èŠ‚çš„å…·ä½“åŠ¨ä½œï¼ˆå¦‚ä¼˜æƒ åˆ¸/æµç¨‹ä¼˜åŒ–ï¼‰+ é¢„æœŸæå‡æ•ˆæœ]
    - æ—¶æ®µè¿è¥ï¼š[é’ˆå¯¹è´­ä¹°é«˜å³°çš„å…·ä½“åŠ¨ä½œï¼ˆå¦‚å®šæ—¶æ¨é€/é™æ—¶æ´»åŠ¨ï¼‰+ é¢„æœŸæå‡æ•ˆæœ]
    - ç”¨æˆ·ç»´æŠ¤ï¼š[é’ˆå¯¹é«˜ä»·å€¼ç”¨æˆ·çš„å…·ä½“åŠ¨ä½œï¼ˆå¦‚ä¼šå‘˜ä½“ç³»/ä¸“å±æƒç›Šï¼‰+ é¢„æœŸæå‡æ•ˆæœ]
    - ç•™å­˜æå‡ï¼š[é’ˆå¯¹ç•™å­˜ç‡çš„å…·ä½“åŠ¨ä½œï¼ˆå¦‚å¤è´­æé†’/æ–°äººç¦åˆ©ï¼‰+ é¢„æœŸæå‡æ•ˆæœ]
    [/INST]"""
    
    try:
        output = llm.create_completion(
            prompt=prompt,
            max_tokens=1000,  # è¶³å¤Ÿå®¹çº³ç»“æ„åŒ–å†…å®¹
            temperature=0.3,  # é™ä½éšæœºæ€§ï¼Œä¿è¯æ ¼å¼ä¸¥æ ¼
            top_p=0.8,        # æ§åˆ¶ç”Ÿæˆå¤šæ ·æ€§ï¼Œé¿å…é‡å¤
            stop=["</s>"],    # ç²¾å‡†æˆªæ–­æ¨¡å‹è¾“å‡ºï¼Œé¿å…å¤šä½™å†…å®¹
            echo=False        # ç¦æ­¢å›æ˜¾Promptå†…å®¹
        )
        # æ¸…ç†è¾“å‡ºï¼ˆç§»é™¤å¯èƒ½çš„å¤šä½™ç©ºæ ¼/æ¢è¡Œï¼‰
        ai_text = output["choices"][0]["text"].strip()

        # æ£€æµ‹è‹±æ–‡å¹¶ç¿»è¯‘
        def contains_english(text):
            return any(char.isalpha() and char.isascii() for char in text)
        
        if contains_english(ai_text):
            # åˆå§‹åŒ–ç¿»è¯‘å™¨ï¼ˆè‹±æ–‡â†’ä¸­æ–‡ï¼‰
            translator = Translator(from_lang="en", to_lang="zh")
            # åˆ†æ®µè½ç¿»è¯‘ï¼ˆé¿å…é•¿æ–‡æœ¬ç¿»è¯‘å¤±è´¥ï¼‰
            translated_paragraphs = []
            for para in ai_text.split('\n'):
                if para.strip():  # è·³è¿‡ç©ºè¡Œ
                    try:
                        translated = translator.translate(para)
                        translated_paragraphs.append(translated)
                    except:
                        translated_paragraphs.append(para)  # ç¿»è¯‘å¤±è´¥æ—¶ä¿ç•™åŸæ–‡
            ai_text = '\n'.join(translated_paragraphs)
        
        return ai_text if ai_text else "AIåˆ†æï¼šæœªç”Ÿæˆæœ‰æ•ˆå†…å®¹ï¼Œè¯·åˆ·æ–°é‡è¯•"
    except Exception as e:
        return f"AIåˆ†æç”Ÿæˆå¤±è´¥ï¼š{str(e)}"

# -------------------------- é¡µé¢åŸºç¡€é…ç½® --------------------------
st.set_page_config(page_title="ç”µå•†ç”¨æˆ·è¡Œä¸ºåˆ†æçœ‹æ¿", layout="wide")
# è§£å†³matplotlibä¸­æ–‡æ˜¾ç¤ºï¼ˆä½¿ç”¨ç³»ç»Ÿå­—ä½“ï¼‰
plt.rcParams["font.sans-serif"] = ["SimSun", "WenQuanYi Micro Hei", "Heiti TC"]
plt.rcParams["axes.unicode_minus"] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜

# -------------------------- MySQLæ•°æ®åº“è¿æ¥ --------------------------
def get_mysql_engine():
    MYSQL_CONFIG = {
        "user": "root",
        "password": "1111",  # æ›¿æ¢ä¸ºä½ çš„MySQLå¯†ç 
        "host": "localhost",
        "port": 3306,
        "database": "ecommerce_analysis"
    }
    return create_engine(
        f"mysql+pymysql://{MYSQL_CONFIG['user']}:{MYSQL_CONFIG['password']}@{MYSQL_CONFIG['host']}:{MYSQL_CONFIG['port']}/{MYSQL_CONFIG['database']}?charset=utf8mb4"
    )

engine = get_mysql_engine()

# -------------------------- ä¾§è¾¹æ é…ç½® --------------------------
st.sidebar.header("ğŸ” ç­›é€‰æ¡ä»¶")

# æ—¥æœŸç­›é€‰
start_date = st.sidebar.date_input(
    "å¼€å§‹æ—¥æœŸ",
    value=datetime(2017, 11, 25).date(),
    min_value=datetime(2017, 11, 25).date(),
    max_value=datetime(2017, 12, 3).date()
)
end_date = st.sidebar.date_input(
    "ç»“æŸæ—¥æœŸ",
    value=datetime(2017, 12, 3).date(),
    min_value=datetime(2017, 11, 25).date(),
    max_value=datetime(2017, 12, 3).date()
)

# Llamaæ¨¡å‹é…ç½®ï¼ˆçº¯CPUï¼‰
st.sidebar.header("ğŸ¤– AIæ¨¡å‹è®¾ç½®")
model_path = st.sidebar.text_input(
    "Llamaæ¨¡å‹è·¯å¾„",
    value=r"F:\ecommerce-user-behavior-analysis\models\llama-2-7b-chat.Q4_K_M.gguf"
)

# åˆå§‹åŒ–session_stateä¸­çš„llmå˜é‡ï¼ˆå…³é”®ä¿®å¤ï¼‰
if 'llm' not in st.session_state:
    st.session_state.llm = None

# è‡ªåŠ¨æ£€æŸ¥æ¨¡å‹æ–‡ä»¶å¹¶åŠ è½½ï¼ˆçº¯CPUï¼‰
if st.session_state.llm is None:
    if os.path.exists(model_path):
        with st.sidebar.status("æ­£åœ¨è‡ªåŠ¨åŠ è½½Llamaæ¨¡å‹..."):
            st.session_state.llm = load_llama_model(model_path)
            if st.session_state.llm:
                st.sidebar.success("æ¨¡å‹åŠ è½½æˆåŠŸï¼ï¼‰")
    else:
        st.sidebar.warning("æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼Œè¯·æ£€æŸ¥è·¯å¾„")
else:
    if st.sidebar.button("é‡æ–°åŠ è½½æ¨¡å‹"):
        with st.spinner("æ­£åœ¨é‡æ–°åŠ è½½Llamaæ¨¡å‹..."):
            st.session_state.llm = load_llama_model(model_path)
        if st.session_state.llm:
            st.sidebar.success("æ¨¡å‹é‡æ–°åŠ è½½æˆåŠŸï¼")

# æ¨¡å‹æ€§èƒ½ç›‘æ§ï¼ˆä»…æ˜¾ç¤ºCPUç›¸å…³ï¼Œç§»é™¤GPUï¼‰
if 'llm' in st.session_state and st.session_state.llm:
    st.sidebar.subheader("æ¨¡å‹çŠ¶æ€")
    try:
        st.sidebar.text(f"ä¸Šä¸‹æ–‡çª—å£: {st.session_state.llm.n_ctx} tokens")
        st.sidebar.text(f"CPUçº¿ç¨‹æ•°: {st.session_state.llm.n_threads}")
        st.sidebar.text("è¿è¡Œæ¨¡å¼: çº¯CPUï¼ˆæ— GPUåŠ é€Ÿï¼‰")
    except AttributeError:
        st.sidebar.text("æ¨¡å‹çŠ¶æ€ï¼šå·²åŠ è½½ï¼ˆå±æ€§æš‚ä¸å¯æŸ¥ï¼‰")

# -------------------------- åŠ è½½ç­›é€‰åçš„æ•°æ® --------------------------
@st.cache_data
def load_behavior_data(start, end):
    sql = f"""
        SELECT * FROM user_behavior 
        WHERE date >= '{start}' AND date <= '{end}'
    """
    return pd.read_sql(sql, engine)

df_filtered = load_behavior_data(start_date, end_date)

# -------------------------- æ ¸å¿ƒæŒ‡æ ‡å±•ç¤º --------------------------
st.title("ğŸ“Š ç”µå•†ç”¨æˆ·è¡Œä¸ºåˆ†æçœ‹æ¿")
st.divider()

# è®¡ç®—ç•™å­˜ç‡å’Œçƒ­é”€å“ç±»
user_retention = calculate_retention(df_filtered)
top_categories = df_filtered[df_filtered["behavior_type"]=="buy"]["category_id"].value_counts().head(3).index.tolist()

# æŒ‡æ ‡å¡ç‰‡ï¼ˆå¢åŠ ç•™å­˜ç‡æŒ‡æ ‡ï¼‰
col1, col2, col3, col4, col5 = st.columns(5)
with col1:
    total_users = df_filtered["user_id"].nunique()
    st.metric("æ€»ç‹¬ç«‹ç”¨æˆ·æ•°", value=f"{total_users:,}")
with col2:
    total_pv = df_filtered[df_filtered["behavior_type"] == "pv"].shape[0]
    st.metric("æ€»æµè§ˆé‡ï¼ˆPVï¼‰", value=f"{total_pv:,}")
with col3:
    total_buy = df_filtered[df_filtered["behavior_type"] == "buy"].shape[0]
    st.metric("æ€»è´­ä¹°é‡", value=f"{total_buy:,}")
with col4:
    conversion = (total_buy / total_pv) * 100 if total_pv > 0 else 0
    st.metric("æ•´ä½“è½¬åŒ–ç‡", value=f"{conversion:.2f}%")
with col5:
    st.metric("æ¬¡æ—¥ç•™å­˜ç‡", value=f"{user_retention:.2f}%")

# -------------------------- è½¬åŒ–æ¼æ–—å›¾è¡¨ --------------------------
st.divider()
st.subheader("è½¬åŒ–æ¼æ–—åˆ†æ")
funnel_data = {
    "æµè§ˆ": df_filtered[df_filtered["behavior_type"] == "pv"]["user_id"].nunique(),
    "æ”¶è—": df_filtered[df_filtered["behavior_type"] == "fav"]["user_id"].nunique(),
    "åŠ è´­": df_filtered[df_filtered["behavior_type"] == "cart"]["user_id"].nunique(),
    "è´­ä¹°": df_filtered[df_filtered["behavior_type"] == "buy"]["user_id"].nunique()
}
funnel_order = ["æµè§ˆ", "æ”¶è—", "åŠ è´­", "è´­ä¹°"]
funnel_values = [funnel_data[s] for s in funnel_order]

fig_funnel = px.funnel(
    x=funnel_values,
    y=funnel_order,
    color=funnel_order,
    color_discrete_sequence=["#FF6B6B", "#4ECDC4", "#45B7D1", "#96CEB4"],
    title="ç”¨æˆ·è¡Œä¸ºè½¬åŒ–æ¼æ–—"
)
st.plotly_chart(fig_funnel, use_container_width=True)

# -------------------------- ç”¨æˆ·åˆ†ç¾¤ + æ—¶æ®µåˆ†æ + çƒ­é”€å“ç±» --------------------------
st.divider()
st.subheader("ç”¨æˆ·åˆ†ç¾¤ & æ—¶æ®µè¡Œä¸º & çƒ­é”€å“ç±»åˆ†æ")
col1, col2, col3 = st.columns(3)  # å¢åŠ ä¸€åˆ—æ˜¾ç¤ºçƒ­é”€å“ç±»

# RFMç”¨æˆ·åˆ†ç¾¤é¥¼å›¾
with col1:
    rfm_df = pd.read_sql("SELECT user_segment FROM user_rfm", engine)
    segment_counts = rfm_df["user_segment"].value_counts()
    fig_pie = px.pie(
        values=segment_counts.values,
        names=segment_counts.index,
        title="RFMç”¨æˆ·åˆ†ç¾¤åˆ†å¸ƒ",
        hole=0.3
    )
    st.plotly_chart(fig_pie, use_container_width=True)

# æ—¶æ®µè¡Œä¸ºåˆ†å¸ƒæŠ˜çº¿å›¾
with col2:
    hourly_behavior = df_filtered.groupby(["hour", "behavior_name"])["user_id"].count().unstack(fill_value=0)
    fig_hour = px.line(
        hourly_behavior,
        x=hourly_behavior.index,
        y=hourly_behavior.columns,
        title="ç”¨æˆ·è¡Œä¸ºæ—¶æ®µåˆ†å¸ƒ",
        labels={"value": "è¡Œä¸ºæ¬¡æ•°", "hour": "å°æ—¶"},
        markers=True
    )
    st.plotly_chart(fig_hour, use_container_width=True)
    # æå–è´­ä¹°é«˜å³°æ—¶æ®µ
    if "buy" in hourly_behavior.columns and not hourly_behavior["buy"].empty:
        buy_peak = hourly_behavior["buy"].idxmax()
    else:
        buy_peak = "æ— æ•°æ®"

# çƒ­é”€å“ç±»TOP5æŸ±çŠ¶å›¾
with col3:
    if not df_filtered[df_filtered["behavior_type"] == "buy"].empty:
        top5_categories = df_filtered[df_filtered["behavior_type"] == "buy"]["category_id"].value_counts().head(5)
        fig_category = px.bar(
            x=top5_categories.index.astype(str),
            y=top5_categories.values,
            title="çƒ­é”€å“ç±»TOP5",
            labels={"x": "å“ç±»ID", "y": "è´­ä¹°æ¬¡æ•°"},
            color=top5_categories.values,
            color_continuous_scale="Viridis"
        )
        st.plotly_chart(fig_category, use_container_width=True)
    else:
        st.info("è¯¥æ—¶æ®µå†…æ— è´­ä¹°æ•°æ®ï¼Œæ— æ³•å±•ç¤ºçƒ­é”€å“ç±»")

# -------------------------- AIåˆ†æå»ºè®® --------------------------
st.divider()
st.subheader("ğŸ¤– AIç”Ÿæˆåˆ†æå»ºè®®")

# å‡†å¤‡åˆ†ææ‰€éœ€æŒ‡æ ‡
metrics = {
    "start_date": start_date,
    "end_date": end_date,
    "total_users": total_users,
    "total_pv": total_pv,
    "total_buy": total_buy,
    "conversion": conversion,
    "funnel_values": funnel_values,
    "buy_peak": buy_peak,
    "high_value_ratio": (segment_counts.get("é«˜ä»·å€¼ç”¨æˆ·", 0) / segment_counts.sum() * 100) if segment_counts.sum() > 0 else 0
}

# ç”ŸæˆAIåˆ†æï¼ˆçº¯CPUï¼‰
ai_analysis = "æœªç”ŸæˆAIåˆ†æ"
if st.session_state.llm:
    with st.spinner("AIæ­£åœ¨åˆ†ææ•°æ®ï¼ˆçº¯CPUï¼Œç¨æ…¢ï¼‰..."):
        ai_analysis = generate_ai_analysis(st.session_state.llm, metrics, df_filtered)
    st.text_area("åˆ†æç»“æœ", value=ai_analysis, height=200, disabled=True)
else:
    st.warning("è¯·å…ˆåŠ è½½Llamaæ¨¡å‹ä»¥è·å–AIåˆ†æå»ºè®®ï¼ˆæ£€æŸ¥æ¨¡å‹è·¯å¾„ï¼‰")

# -------------------------- æŠ¥å‘Šå¯¼å‡ºåŠŸèƒ½ --------------------------
st.divider()
st.subheader("ğŸ“‘ æŠ¥å‘Šå¯¼å‡º")

if st.button("ç”ŸæˆPDFåˆ†ææŠ¥å‘Š"):
    with st.spinner("æ­£åœ¨ç”ŸæˆPDFæŠ¥å‘Š..."):
        # å‡†å¤‡æŠ¥å‘Šæ‰€éœ€æ•°æ®
        pdf_path = generate_chinese_pdf(
            start_date=start_date,
            end_date=end_date,
            total_users=total_users,
            total_pv=total_pv,
            total_buy=total_buy,
            conversion=conversion,
            funnel_order=funnel_order,
            funnel_values=funnel_values,
            segment_counts=segment_counts,
            buy_peak=buy_peak,
            ai_analysis=ai_analysis,
            top_categories=top_categories,
            user_retention=user_retention
        )
    if pdf_path:
        st.success(f"PDFæŠ¥å‘Šå·²ç”Ÿæˆï¼š{pdf_path}")
        # æä¾›ä¸‹è½½åŠŸèƒ½
        with open(pdf_path, "rb") as f:
            st.download_button(
                label="ä¸‹è½½PDFæŠ¥å‘Š",
                data=f,
                file_name="ç”µå•†ç”¨æˆ·åˆ†ææŠ¥å‘Š.pdf",
                mime="application/pdf"
            )
    else:
        st.error("PDFæŠ¥å‘Šç”Ÿæˆå¤±è´¥")

# -------------------------- æ•°æ®é¢„è§ˆ --------------------------
st.divider()
with st.expander("ğŸ“ æŸ¥çœ‹åŸå§‹æ•°æ®ï¼ˆå‰100è¡Œï¼‰"):
    st.dataframe(df_filtered.head(100), use_container_width=True)